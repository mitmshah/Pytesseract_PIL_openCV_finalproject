{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Project #\n",
    "1. This is a project with minimal scaffolding. Expect to use the the discussion forums to gain insights! Itâ€™s not cheating to ask others for opinions or perspectives!\n",
    "2. Be inquisitive, try out new things.\n",
    "3. Use the previous modules for insights into how to complete the functions! You'll have to combine Pillow, OpenCV, and Pytesseract\n",
    "4. There are hints provided in Coursera, feel free to explore the hints if needed. Each hint provide progressively more details on how to solve the issue. This project is intended to be comprehensive and difficult if you do it without the hints.\n",
    "\n",
    "### The Assignment ###\n",
    "Take a [ZIP file](https://en.wikipedia.org/wiki/Zip_(file_format)) of images and process them, using a [library built into python](https://docs.python.org/3/library/zipfile.html) that you need to learn how to use. A ZIP file takes several different files and compresses them, thus saving space, into one single file. The files in the ZIP file we provide are newspaper images (like you saw in week 3). Your task is to write python code which allows one to search through the images looking for the occurrences of keywords and faces. E.g. if you search for \"pizza\" it will return a contact sheet of all of the faces which were located on the newspaper page which mentions \"pizza\". This will test your ability to learn a new ([library](https://docs.python.org/3/library/zipfile.html)), your ability to use OpenCV to detect faces, your ability to use tesseract to do optical character recognition, and your ability to use PIL to composite images together into contact sheets.\n",
    "\n",
    "Each page of the newspapers is saved as a single PNG image in a file called [images.zip](./readonly/images.zip). These newspapers are in english, and contain a variety of stories, advertisements and images. Note: This file is fairly large (~200 MB) and may take some time to work with, I would encourage you to use [small_img.zip](./readonly/small_img.zip) for testing.\n",
    "\n",
    "Here's an example of the output expected. Using the [small_img.zip](./readonly/small_img.zip) file, if I search for the string \"Christopher\" I should see the following image:\n",
    "![Christopher Search](./readonly/small_project.png)\n",
    "If I were to use the [images.zip](./readonly/images.zip) file and search for \"Mark\" I should see the following image (note that there are times when there are no faces on a page, but a word is found!):\n",
    "![Mark Search](./readonly/large_project.png)\n",
    "\n",
    "Note: That big file can take some time to process - for me it took nearly ten minutes! Use the small one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "# loading the face detection classifier\n",
    "face_cascade = cv.CascadeClassifier('readonly/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# To get contact sheet for the image from the originial image\n",
    "def getcontactsheet(box,image):\n",
    "    \n",
    "    contact_sheet = Image.new(image.mode,(550,110*(int(box.shape[0]/5)+1)))\n",
    "    height= 0\n",
    "    length = 0\n",
    "    for x,y,w,h in box:\n",
    "        img = image.crop(box=[x,y,x+w,y+h])\n",
    "        img.thumbnail((110,110))\n",
    "        contact_sheet.paste(img,(length,height))\n",
    "        if length + img.width == contact_sheet.width:\n",
    "            length = 0\n",
    "            height = height + img.height\n",
    "        else:\n",
    "            length = length + img.width\n",
    "    display(contact_sheet)\n",
    "    \n",
    "# the rest is up to you!\n",
    "\n",
    "# Opening both the files (images.zip and small_img.zip)\n",
    "small_file = zipfile.ZipFile('readonly/small_img.zip')\n",
    "big_file = zipfile.ZipFile('readonly/images.zip')\n",
    "\n",
    "\n",
    "###### Image,string and name datastructure ##############3\n",
    "Image_list = {}\n",
    "converted_string_ocr = {}\n",
    "newspaper_list = []\n",
    "\n",
    "# which file we are gonna go through\n",
    "file = big_file\n",
    "\n",
    "# Converts every newspaper to strings using pytesseract. Saving the image file and the newspaper_list that we want to find the faces on\n",
    "\n",
    "for i, newspaper in enumerate(file.infolist()):\n",
    "    Image_list[newspaper.filename] = Image.open(file.open(newspaper.filename))\n",
    "    newspaper_list.append(newspaper.filename)\n",
    "    converted_string_ocr[newspaper.filename] = pytesseract.image_to_string(Image_list[newspaper.filename].convert('L')).replace('-\\n','')\n",
    "\n",
    "# Takes user input for the word to be found\n",
    "randomsearch = input(\"Enter the word: \")\n",
    "\n",
    "faces = {}\n",
    "# Going through each newspaper to find whether the given word in that newspaper or not\n",
    "for i, newspaper in enumerate(newspaper_list):\n",
    "    \n",
    "    # Finds whether the given word is in which newspaper\n",
    "    if randomsearch in converted_string_ocr[newspaper]:\n",
    "        print(\"Results found in File \",  newspaper)\n",
    "        faces[newspaper]= face_cascade.detectMultiScale(np.array(Image_list[newspaper]),1.35,4)\n",
    "        if not(faces[newspaper].shape[0] == 0):\n",
    "            getcontactsheet(faces[newspaper],Image_list[newspaper])\n",
    "    else:\n",
    "        print(\"Results Not found in File \", newspaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-0.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dca115c1b2cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewspaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m\"Bill\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconverted_string_ocr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewspaper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"there\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function detectMultiScale:\n",
      "\n",
      "detectMultiScale(...) method of cv2.CascadeClassifier instance\n",
      "    detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects\n",
      "    .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "    .   of rectangles.\n",
      "    .   \n",
      "    .   @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "    .   @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "    .   rectangles may be partially outside the original image.\n",
      "    .   @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "    .   @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "    .   to retain it.\n",
      "    .   @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "    .   cvHaarDetectObjects. It is not used for a new cascade.\n",
      "    .   @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "    .   @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "    .   \n",
      "    .   The function is parallelized with the TBB library.\n",
      "    .   \n",
      "    .   @note\n",
      "    .   -   (Python) A face detection example using cascade classifiers can be found at\n",
      "    .   opencv_source_code/samples/python/facedetect.py\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
